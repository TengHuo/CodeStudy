{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script handling the training process.\n",
    "'''\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import transformer.Constants as Constants\n",
    "from dataset import TranslationDataset, paired_collate_fn\n",
    "from transformer.Models import Transformer\n",
    "from transformer.Optim import ScheduledOptim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(pred, gold, smoothing=False):\n",
    "    ''' Apply label smoothing if needed '''\n",
    "\n",
    "    loss = cal_loss(pred, gold, smoothing)\n",
    "\n",
    "    pred = pred.max(1)[1]\n",
    "    gold = gold.contiguous().view(-1)\n",
    "    non_pad_mask = gold.ne(Constants.PAD)\n",
    "    n_correct = pred.eq(gold)\n",
    "    n_correct = n_correct.masked_select(non_pad_mask).sum().item()\n",
    "\n",
    "    return loss, n_correct\n",
    "\n",
    "\n",
    "def cal_loss(pred, gold, smoothing):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "\n",
    "    gold = gold.contiguous().view(-1)\n",
    "\n",
    "    if smoothing:\n",
    "        eps = 0.1\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        non_pad_mask = gold.ne(Constants.PAD)\n",
    "        loss = -(one_hot * log_prb).sum(dim=1)\n",
    "        loss = loss.masked_select(non_pad_mask).sum()  # average later\n",
    "    else:\n",
    "        loss = F.cross_entropy(pred, gold, ignore_index=Constants.PAD, reduction='sum')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, training_data, optimizer, device, smoothing):\n",
    "    ''' Epoch operation in training phase'''\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    n_word_total = 0\n",
    "    n_word_correct = 0\n",
    "\n",
    "    for batch in tqdm(\n",
    "            training_data, mininterval=2,\n",
    "            desc='  - (Training)   ', leave=False):\n",
    "        \n",
    "        # prepare data\n",
    "        src_seq, src_pos, tgt_seq, tgt_pos = map(lambda x: x.to(device), batch)\n",
    "        gold = tgt_seq[:, 1:]\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src_seq, src_pos, tgt_seq, tgt_pos)\n",
    "\n",
    "        # backward\n",
    "        loss, n_correct = cal_performance(pred, gold, smoothing=smoothing)\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step_and_update_lr()\n",
    "\n",
    "        # note keeping\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        non_pad_mask = gold.ne(Constants.PAD)\n",
    "        n_word = non_pad_mask.sum().item()\n",
    "        n_word_total += n_word\n",
    "        n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, validation_data, device):\n",
    "    ''' Epoch operation in evaluation phase '''\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    n_word_total = 0\n",
    "    n_word_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(\n",
    "                validation_data, mininterval=2,\n",
    "                desc='  - (Validation) ', leave=False):\n",
    "\n",
    "            # prepare data\n",
    "            src_seq, src_pos, tgt_seq, tgt_pos = map(lambda x: x.to(device), batch)\n",
    "            gold = tgt_seq[:, 1:]\n",
    "\n",
    "            # forward\n",
    "            pred = model(src_seq, src_pos, tgt_seq, tgt_pos)\n",
    "            loss, n_correct = cal_performance(pred, gold, smoothing=False)\n",
    "\n",
    "            # note keeping\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            non_pad_mask = gold.ne(Constants.PAD)\n",
    "            n_word = non_pad_mask.sum().item()\n",
    "            n_word_total += n_word\n",
    "            n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss/n_word_total\n",
    "    accuracy = n_word_correct/n_word_total\n",
    "    return loss_per_word, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, validation_data, optimizer, device, opt):\n",
    "    ''' Start training '''\n",
    "\n",
    "    log_train_file = None\n",
    "    log_valid_file = None\n",
    "\n",
    "    if opt['log']:\n",
    "        log_train_file = opt['log'] + '.train.log'\n",
    "        log_valid_file = opt['log'] + '.valid.log'\n",
    "\n",
    "        print('[Info] Training performance will be written to file: {} and {}'.format(\n",
    "            log_train_file, log_valid_file))\n",
    "\n",
    "        with open(log_train_file, 'w') as log_tf, open(log_valid_file, 'w') as log_vf:\n",
    "            log_tf.write('epoch,loss,ppl,accuracy\\n')\n",
    "            log_vf.write('epoch,loss,ppl,accuracy\\n')\n",
    "\n",
    "    valid_accus = []\n",
    "    for epoch_i in range(opt['epoch']):\n",
    "        print('[ Epoch', epoch_i, ']')\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss, train_accu = train_epoch(\n",
    "            model, training_data, optimizer, device, smoothing=opt['label_smoothing'])\n",
    "        print('  - (Training)   ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, '\\\n",
    "              'elapse: {elapse:3.3f} min'.format(\n",
    "                  ppl=math.exp(min(train_loss, 100)), accu=100*train_accu,\n",
    "                  elapse=(time.time()-start)/60))\n",
    "\n",
    "        start = time.time()\n",
    "        valid_loss, valid_accu = eval_epoch(model, validation_data, device)\n",
    "        print('  - (Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, '\\\n",
    "                'elapse: {elapse:3.3f} min'.format(\n",
    "                    ppl=math.exp(min(valid_loss, 100)), accu=100*valid_accu,\n",
    "                    elapse=(time.time()-start)/60))\n",
    "\n",
    "        valid_accus += [valid_accu]\n",
    "\n",
    "        model_state_dict = model.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            'settings': opt,\n",
    "            'epoch': epoch_i}\n",
    "\n",
    "        if opt['save_model']:\n",
    "            if opt['save_mode'] == 'all':\n",
    "                model_name = opt.save_model + '_accu_{accu:3.3f}.chkpt'.format(accu=100*valid_accu)\n",
    "                torch.save(checkpoint, model_name)\n",
    "            elif opt['save_mode'] == 'best':\n",
    "                model_name = opt['save_model'] + '.chkpt'\n",
    "                if valid_accu >= max(valid_accus):\n",
    "                    torch.save(checkpoint, model_name)\n",
    "                    print('    - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "        if log_train_file and log_valid_file:\n",
    "            with open(log_train_file, 'a') as log_tf, open(log_valid_file, 'a') as log_vf:\n",
    "                log_tf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                    epoch=epoch_i, loss=train_loss,\n",
    "                    ppl=math.exp(min(train_loss, 100)), accu=100*train_accu))\n",
    "                log_vf.write('{epoch},{loss: 8.5f},{ppl: 8.5f},{accu:3.3f}\\n'.format(\n",
    "                    epoch=epoch_i, loss=valid_loss,\n",
    "                    ppl=math.exp(min(valid_loss, 100)), accu=100*valid_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(data, batch_size):\n",
    "    # ========= Preparing DataLoader =========#\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TranslationDataset(\n",
    "            src_word2idx=data['dict']['src'],\n",
    "            tgt_word2idx=data['dict']['tgt'],\n",
    "            src_insts=data['train']['src'],\n",
    "            tgt_insts=data['train']['tgt']),\n",
    "        num_workers=2,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=paired_collate_fn,\n",
    "        shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        TranslationDataset(\n",
    "            src_word2idx=data['dict']['src'],\n",
    "            tgt_word2idx=data['dict']['tgt'],\n",
    "            src_insts=data['valid']['src'],\n",
    "            tgt_insts=data['valid']['tgt']),\n",
    "        num_workers=2,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=paired_collate_fn)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911\n",
      "3149\n"
     ]
    }
   ],
   "source": [
    "# python train.py -data data/multi30k.atok.low.pt \n",
    "#                 -save_model trained\n",
    "#                 -save_mode best\n",
    "#                 -proj_share_weight\n",
    "#                 -label_smoothing\n",
    "\n",
    "opt = {'data': 'data/multi30k.atok.low.pt',\n",
    "       'epoch': 10,\n",
    "       'batch_size': 16,\n",
    "       'd_model': 512,\n",
    "       'd_inner_hid': 2048,\n",
    "       'd_k': 64,\n",
    "       'd_v': 64,\n",
    "       'n_head': 8,\n",
    "       'n_layers': 6,\n",
    "       'n_warmup_steps': 4000,\n",
    "       'dropout': 0.1,\n",
    "       'embs_share_weight': False,\n",
    "       'proj_share_weight': True,\n",
    "       'log': None,\n",
    "       'save_model': 'trained',\n",
    "       'save_mode': 'best',\n",
    "       'no_cuda': True,\n",
    "       'label_smoothing': True}\n",
    "\n",
    "opt['cuda'] = not opt['no_cuda']\n",
    "opt['d_word_vec'] = opt['d_model']\n",
    "\n",
    "#========= Loading Dataset =========#\n",
    "data = torch.load(opt['data'])\n",
    "opt['max_token_seq_len'] = data['settings'].max_token_seq_len\n",
    "\n",
    "training_data, validation_data = prepare_dataloaders(data, opt['batch_size'])\n",
    "\n",
    "opt['src_vocab_size'] = training_data.dataset.src_vocab_size\n",
    "opt['tgt_vocab_size'] = training_data.dataset.tgt_vocab_size\n",
    "\n",
    "print(opt['src_vocab_size'])\n",
    "print(opt['tgt_vocab_size'])\n",
    "\n",
    "#========= Preparing Model =========#\n",
    "if opt['embs_share_weight']:\n",
    "    assert training_data.dataset.src_word2idx == training_data.dataset.tgt_word2idx, \\\n",
    "        'The src/tgt word2idx table are different but asked to share word embedding.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 24])\n",
      "\n",
      "torch.Size([16, 24])\n",
      "\n",
      "torch.Size([16, 23])\n",
      "\n",
      "torch.Size([16, 23])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in training_data:\n",
    "    for j in i:\n",
    "        print(j.size())\n",
    "        print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "[2, 2782, 683, 291, 77, 2376, 2501, 2987, 2800, 2105, 818, 1, 1, 1177, 3]\n",
      "[2, 3116, 77, 1208, 2867, 2559, 674, 1, 1177, 3]\n",
      "[2, 674, 54, 404, 3066, 2800, 674, 1, 2935, 312, 1177, 3]\n",
      "[2, 674, 1217, 2800, 170, 2380, 2716, 2268, 2303, 2812, 987, 1460, 1486, 674, 990, 1177, 3]\n",
      "[2, 2782, 77, 2355, 1793, 1063, 1460, 2519, 2427, 245, 1177, 3]\n",
      "[2, 674, 1217, 2800, 904, 86, 2423, 1454, 1942, 82, 2105, 1616, 1217, 142, 2716, 2553, 1177, 3]\n",
      "[2, 674, 1217, 1253, 973, 1, 1, 2555, 1177, 3]\n",
      "[2, 674, 1, 404, 1223, 1208, 2579, 3125, 82, 2999, 1, 1580, 431, 1, 1177, 3]\n",
      "[2, 2423, 604, 1208, 2812, 749, 1614, 2084, 2555, 170, 1300, 1384, 1177, 3]\n",
      "[2, 2499, 667, 358, 2800, 2105, 2664, 2303, 2557, 1177, 3]\n",
      "[2, 2423, 1, 1208, 2056, 404, 1942, 1580, 1, 1866, 1177, 3]\n"
     ]
    }
   ],
   "source": [
    "train_data = data['train']['tgt']\n",
    "print(len(train_data))\n",
    "\n",
    "for i in range(0, len(train_data)):\n",
    "    print(train_data[i])\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n",
      "[2, 2199, 759, 1936, 1761, 1107, 2561, 1925, 355, 2199, 1023, 3]\n",
      "[2, 2199, 1595, 2303, 2591, 2199, 1855, 809, 1014, 2199, 1556, 1096, 3]\n",
      "[2, 2199, 14, 614, 2620, 585, 1014, 2199, 1883, 1391, 1064, 1096, 3]\n",
      "[2, 1876, 1761, 1618, 201, 2199, 1330, 643, 1832, 2042, 1014, 2371, 1, 2214, 2117, 3]\n",
      "[2, 2199, 2267, 1595, 614, 2199, 96, 2411, 2435, 2763, 1573, 2591, 2199, 1413, 650, 1096, 3]\n",
      "[2, 2199, 2866, 2591, 2199, 96, 661, 1783, 2633, 2199, 1, 1114, 2708, 1, 1936, 2845, 1768, 1783, 543, 1409, 268, 720, 1063, 2199, 1, 1096, 3]\n",
      "[2, 2199, 680, 1967, 2763, 2784, 79, 268, 985, 1967, 1096, 3]\n",
      "[2, 2199, 711, 14, 614, 2199, 1, 613, 957, 2199, 1569, 1133, 2336, 2371, 1, 141, 1096, 3]\n",
      "[2, 2199, 1595, 2591, 2199, 2822, 1983, 2763, 1415, 268, 764, 3]\n",
      "[2, 2199, 182, 1883, 2591, 2199, 1, 1240, 430, 2230, 2633, 2199, 416, 482, 3]\n",
      "[2, 2199, 711, 1332, 2763, 1075, 2103, 1014, 1809, 1, 1750, 1096, 3]\n"
     ]
    }
   ],
   "source": [
    "valid_data = data['valid']['src']\n",
    "print(len(valid_data))\n",
    "\n",
    "for i in range(0, len(valid_data)):\n",
    "    print(valid_data[i])\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149\n",
      "<s>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dict_data = data['dict']['tgt']\n",
    "print(len(dict_data))\n",
    "\n",
    "for k, v in dict_data.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if opt['cuda'] else 'cpu')\n",
    "print(device)\n",
    "\n",
    "transformer = Transformer(\n",
    "    opt['src_vocab_size'],\n",
    "    opt['tgt_vocab_size'],\n",
    "    opt['max_token_seq_len'],\n",
    "    tgt_emb_prj_weight_sharing=opt['proj_share_weight'],\n",
    "    emb_src_tgt_weight_sharing=opt['embs_share_weight'],\n",
    "    d_k=opt['d_k'],\n",
    "    d_v=opt['d_v'],\n",
    "    d_model=opt['d_model'],\n",
    "    d_word_vec=opt['d_word_vec'],\n",
    "    d_inner=opt['d_inner_hid'],\n",
    "    n_layers=opt['n_layers'],\n",
    "    n_head=opt['n_head'],\n",
    "    dropout=opt['dropout']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      "data/multi30k.atok.low.pt\n",
      "\n",
      "dict_keys(['data', 'epoch', 'batch_size', 'd_model', 'd_inner_hid', 'd_k', 'd_v', 'n_head', 'n_layers', 'n_warmup_steps', 'dropout', 'embs_share_weight', 'proj_share_weight', 'log', 'save_model', 'save_mode', 'no_cuda', 'label_smoothing', 'cuda', 'd_word_vec', 'max_token_seq_len', 'src_vocab_size', 'tgt_vocab_size'])\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for key in opt:\n",
    "    print('{}: \\n{}\\n'.format(key, opt[key]))\n",
    "    break\n",
    "    \n",
    "print(opt.keys())\n",
    "print(opt['batch_size'])\n",
    "\n",
    "# d_model的512应该是word embedding的长度，一个word用512个长度的vector表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  - (Training)   :   0%|          | 0/1813 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 0 ]\n",
      "SIZE:\n",
      "torch.Size([16, 25, 3149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  - (Training)   :   0%|          | 1/1813 [00:02<1:08:14,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE:\n",
      "torch.Size([16, 20, 3149])\n",
      "SIZE:\n",
      "torch.Size([16, 23, 3149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  - (Training)   :   0%|          | 3/1813 [00:06<1:05:58,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE:\n",
      "torch.Size([16, 21, 3149])\n",
      "SIZE:\n",
      "torch.Size([16, 24, 3149])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  - (Training)   :   0%|          | 5/1813 [00:10<1:03:30,  2.11s/it]Traceback (most recent call last):\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/miniconda3/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6ccd5bba1243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# TODO: 写一个只包含encoder的transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9fa0c8dc2f8a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, training_data, validation_data, optimizer, device, opt)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         train_loss, train_accu = train_epoch(\n\u001b[0;32m---> 24\u001b[0;31m             model, training_data, optimizer, device, smoothing=opt['label_smoothing'])\n\u001b[0m\u001b[1;32m     25\u001b[0m         print('  - (Training)   ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, '\\\n\u001b[1;32m     26\u001b[0m               'elapse: {elapse:3.3f} min'.format(\n",
      "\u001b[0;32m<ipython-input-3-830f7853a404>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, training_data, optimizer, device, smoothing)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/CodePractice/transformer_emg/src/transformer/Models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, src_pos, tgt_seq, tgt_pos)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mseq_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_word_prj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_logit_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SIZE:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/CodePractice/transformer_emg/src/transformer/Models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt_seq, tgt_pos, src_seq, enc_output, return_attns)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mnon_pad_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mslf_attn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslf_attn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 dec_enc_attn_mask=dec_enc_attn_mask)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_attns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/CodePractice/transformer_emg/src/transformer/Layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_input, enc_output, non_pad_mask, slf_attn_mask, dec_enc_attn_mask)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnon_pad_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnon_pad_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/CodePractice/transformer_emg/src/transformer/SubLayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 187\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = ScheduledOptim(\n",
    "    optim.Adam(\n",
    "        filter(lambda x: x.requires_grad, transformer.parameters()),\n",
    "        betas=(0.9, 0.98), eps=1e-09),\n",
    "    opt['d_model'], opt['n_warmup_steps'])\n",
    "\n",
    "# TODO: 研究data的输入和输出，写一个dataloader\n",
    "# TODO: 写一个只包含encoder的transformer\n",
    "\n",
    "train(transformer, training_data, validation_data, optimizer, device, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
